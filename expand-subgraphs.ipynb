{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a9a4a0",
   "metadata": {},
   "source": [
    "To ensure that every samples has GO annotations that represent a complete subgraph of the Gene Ontology, we'll leverage the hierarchical structure of the GO DAG to include terms of any missing descendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6487a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import obonet\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "all_dataset_path = \"./dataset/all-filtered.jsonl\"\n",
    "mf_dataset_path = \"./dataset/mf-filtered.jsonl\"\n",
    "bp_dataset_path = \"./dataset/bp-filtered.jsonl\"\n",
    "cc_dataset_path = \"./dataset/cc-filtered.jsonl\"\n",
    "\n",
    "all_expanded_path = \"./dataset/all-expanded.jsonl\"\n",
    "mf_expanded_path = \"./dataset/mf-expanded.jsonl\"\n",
    "bp_expanded_path = \"./dataset/bp-expanded.jsonl\"\n",
    "cc_expanded_path = \"./dataset/cc-expanded.jsonl\"\n",
    "\n",
    "top_k = 30\n",
    "\n",
    "go_obo_path = \"./dataset/go-basic.obo\"\n",
    "\n",
    "graph = obonet.read_obo(go_obo_path)\n",
    "\n",
    "MF_ROOT_NODE = \"GO:0003674\"\n",
    "BP_ROOT_NODE = \"GO:0008150\"\n",
    "CC_ROOT_NODE = \"GO:0005575\"\n",
    "\n",
    "if not nx.is_directed_acyclic_graph(graph):\n",
    "    raise ValueError(\"Invalid gene ontology graph, must not contain cycles.\")\n",
    "\n",
    "for name, dataset_path, expanded_path, root_nodes in [\n",
    "    (\"All\", all_dataset_path, all_expanded_path, {MF_ROOT_NODE, BP_ROOT_NODE, CC_ROOT_NODE}),\n",
    "    (\"Molecular Function\", mf_dataset_path, mf_expanded_path, {MF_ROOT_NODE,}),\n",
    "    (\"Biological Process\", bp_dataset_path, bp_expanded_path, {BP_ROOT_NODE,}),\n",
    "    (\"Cellular Component\", cc_dataset_path, cc_expanded_path, {CC_ROOT_NODE,}),\n",
    "]:\n",
    "    dataset = load_dataset(\"json\", data_files=dataset_path, split=\"train\")\n",
    "\n",
    "    before_counter = Counter()\n",
    "    after_counter = Counter()\n",
    "\n",
    "    with open(expanded_path, \"w\") as file:\n",
    "        for record in dataset:\n",
    "            original_terms = set(record[\"go_terms\"])\n",
    "\n",
    "            for term in original_terms:\n",
    "                before_counter[term] += 1\n",
    "\n",
    "            node_ids = root_nodes | original_terms\n",
    "\n",
    "            subgraph = graph.subgraph(node_ids)\n",
    "\n",
    "            if not nx.is_directed_acyclic_graph(subgraph):\n",
    "                continue\n",
    "\n",
    "            expanded_terms = set()\n",
    "\n",
    "            for node in subgraph.nodes:\n",
    "                expanded_terms.add(node)\n",
    "\n",
    "                for descendant in nx.descendants(subgraph, node):\n",
    "                    expanded_terms.add(descendant)\n",
    "\n",
    "            if not expanded_terms.difference(root_nodes):\n",
    "                continue\n",
    "\n",
    "            for term in expanded_terms:\n",
    "                after_counter[term] += 1\n",
    "            \n",
    "            record[\"go_terms\"] = list(expanded_terms)\n",
    "\n",
    "            file.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "    for when, counter, in ((\"Before\", before_counter), (\"After\", after_counter)):\n",
    "        counter = dict(sorted(counter.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        first_k = dict(islice(counter.items(), top_k))\n",
    "\n",
    "        plt.figure(figsize=(12, 5)) \n",
    "\n",
    "        plt.bar(first_k.keys(), first_k.values())\n",
    "\n",
    "        plt.title(f\"Top {top_k} {name} Terms {when} Expansion\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel(\"GO Term ID\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    total_before = before_counter.total()\n",
    "    total_after = after_counter.total()\n",
    "\n",
    "    unique_before = len(before_counter)\n",
    "    unique_after = len(after_counter)\n",
    "\n",
    "    average_before = total_before / unique_before\n",
    "    average_after = total_after / unique_after\n",
    "\n",
    "    orphaned_terms = unique_before - unique_after\n",
    "\n",
    "    print(f\"Total terms before/after: {total_before:,}/{total_after:,}\")\n",
    "    print(f\"Average terms before/after: {average_before:.2f}/{average_after:.2f}\")\n",
    "    print(f\"Invalid/deprecated terms: {orphaned_terms:,}\")\n",
    "\n",
    "    print(f\"Dataset saved to {expanded_path}\")\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
